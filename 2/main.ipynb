{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-04T09:59:37.189041Z",
     "start_time": "2024-10-04T09:59:37.186330Z"
    }
   },
   "source": [
    "import re\n",
    "import os\n",
    "from math import log"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:59:37.203931Z",
     "start_time": "2024-10-04T09:59:37.200848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize(text):\n",
    "    text = re.sub(\"[^A-Za-z]\", \" \", text)\n",
    "    text = re.sub(\" +\", \" \", text).strip()\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def get_occurrence(sets, word):\n",
    "    occurrence = 0\n",
    "    for set_ in sets:\n",
    "        if word in set_:\n",
    "            occurrence += 1\n",
    "\n",
    "    return occurrence\n"
   ],
   "id": "60c736d10df41ff0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:59:37.219426Z",
     "start_time": "2024-10-04T09:59:37.212678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Classify:\n",
    "    def __init__(self):\n",
    "        self.spam_samples = []\n",
    "        self.ham_samples = []\n",
    "        self.size = 0\n",
    "\n",
    "        self._p_spam = 0.5\n",
    "        self._p_ham = 0.5\n",
    "\n",
    "    def _p_word_spam(self, word):\n",
    "        return (get_occurrence(self.spam_samples, word) + 1) / (self.size + 2)\n",
    "\n",
    "    def _p_word_ham(self, word):\n",
    "        return (get_occurrence(self.ham_samples, word) + 1) / (self.size + 2)\n",
    "\n",
    "    def _p_text_spam(self, text):\n",
    "        p = 1\n",
    "        for word in text.split():\n",
    "            if self._p_word_spam(word) != 0:\n",
    "                p *= self._p_word_spam(word)\n",
    "\n",
    "        return p\n",
    "\n",
    "    def _p_text_ham(self, text):\n",
    "        p = 1\n",
    "        for word in text.split():\n",
    "            if self._p_word_ham(word) != 0:\n",
    "                p *= self._p_word_ham(word)\n",
    "\n",
    "        return p\n",
    "\n",
    "    def train(self, spam_files_folders, ham_files_folders, size):\n",
    "        for spam_files_folder, ham_files_folder in zip(spam_files_folders, ham_files_folders):\n",
    "            spam_samples = os.walk(spam_files_folder).__next__()[2][:size]\n",
    "            ham_samples = os.walk(ham_files_folder).__next__()[2][:size]\n",
    "    \n",
    "            self.spam_samples += [\n",
    "                set(\n",
    "                    normalize(\n",
    "                        open(spam_files_folder + '/' + i, errors='ignore').read()\n",
    "                    ).split()[1:]\n",
    "                ) for i in spam_samples\n",
    "            ]\n",
    "            self.ham_samples += [\n",
    "                set(\n",
    "                    normalize(\n",
    "                        open(ham_files_folder + '/' + i, errors='ignore').read()\n",
    "                    ).split()[1:]\n",
    "                ) for i in ham_samples]\n",
    "    \n",
    "            self.size += size\n",
    "\n",
    "    def predict(self, text):\n",
    "        # print(self._p_text_spam(text) * self._p_spam)\n",
    "        # print(self._p_text_ham(text) * self._p_ham)\n",
    "\n",
    "        if self._p_text_spam(text) * self._p_spam == 0 or self._p_text_ham(text) * self._p_ham == 0:\n",
    "            return 'none'\n",
    "\n",
    "        if log(self._p_text_spam(text) * self._p_spam) > log(self._p_text_ham(text) * self._p_ham):\n",
    "            # print(self._p_text_spam(text) * self._p_spam, self._p_text_ham(text) * self._p_ham)\n",
    "            return 'spam'\n",
    "        return 'ham'\n",
    "\n"
   ],
   "id": "85f33292b5dccd69",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:59:38.990594Z",
     "start_time": "2024-10-04T09:59:37.237494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cl = Classify()\n",
    "\n",
    "train_data_size = 1200\n",
    "\n",
    "cl.train(spam_files_folders=['enron1/spam', 'enron2/spam'], ham_files_folders=['enron1/ham', 'enron2/ham'], size=train_data_size)"
   ],
   "id": "bc4bb3d3aae0df68",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:59:39.024494Z",
     "start_time": "2024-10-04T09:59:39.002428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "body = \"\"\"subject how are you now loading no more messages\"\"\"\n",
    "\n",
    "print(cl.predict(normalize(body)))"
   ],
   "id": "86097df5cc53069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:59:39.203762Z",
     "start_time": "2024-10-04T09:59:39.045342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_data_size = 300  # 300 - max (не хватит писем в датасете)\n",
    "\n",
    "spam_samples = [\n",
    "    normalize(\n",
    "        open('enron1/spam/' + i, errors='ignore').read()\n",
    "    ) for i in os.walk(\"enron1/spam\").__next__()[2][train_data_size:test_data_size+train_data_size]\n",
    "]\n",
    "\n",
    "ham_samples = [\n",
    "    normalize(\n",
    "        open('enron1/ham/' + i, errors='ignore').read()\n",
    "    ) for i in os.walk(\"enron1/ham\").__next__()[2][train_data_size:test_data_size+train_data_size]\n",
    "]\n"
   ],
   "id": "faccb45918e5b693",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:00:37.400010Z",
     "start_time": "2024-10-04T09:59:39.210930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classified = 0\n",
    "err = 0\n",
    "failed = 0\n",
    "\n",
    "for samples, _class in [(spam_samples, 'spam'), (ham_samples, 'ham')]:\n",
    "    for sample in samples:\n",
    "        rs = cl.predict(sample)\n",
    "        if rs == _class:\n",
    "            classified += 1\n",
    "        elif rs == 'none':\n",
    "            err += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "            \n",
    "print(f\"Classified {classified} out of {failed} failed. Error: {err}.\")"
   ],
   "id": "e0148fe31430370e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified 427 out of 13 failed. Error: 160.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:00:37.474909Z",
     "start_time": "2024-10-04T10:00:37.471936Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Accuracy: {(classified / (test_data_size * 2)) * 100:.2f}%\")",
   "id": "43e2aca40745e51f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.17%\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
